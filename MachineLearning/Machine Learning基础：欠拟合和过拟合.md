# Machine Learning基础：欠拟合和过拟合

<br>
<br>

## 1 欠拟合

欠拟合是指模型拟合程度不高，数据距离拟合曲线较远，或指数据没有很好地捕捉到数据特征，不能够很好地拟合数据。

如果模型在训练集中表现较差，在测试集中表现同样差，这可能是欠拟合导致。

** 解决方法：**

（1）增加新特征：可以考虑加入进特征组合、高次特征，来增大假设空间；

（2）添加多项式特征：这个在机器学习算法里面用的很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强；

（3）减少正则化参数：正则化的目的是用来防止过拟合的，但是模型出现了欠拟合，则需要减少正则化参数；

（4）使用非线性模型：比如核SVM 、决策树、深度学习等模型；

（5）调整模型的容量（capacity）：通俗地，模型的容量是指其拟合各种函数的能力。容量低的模型可能很难拟合训练集；使用集成学习方法，如Bagging ,将多个弱学习器Bagging。


## 2 过拟合

![](https://upload-images.jianshu.io/upload_images/10947003-fc46e512b7696b86.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600)

&emsp;&emsp;过拟合指的是referstoa模型对于训练数据拟合程度过当的情况。

** 原因：**

（1）噪声：永远没有完美的数据，数据里的噪声会影响模型的学习。

（2）假规律： 样本量较少时，学习器却很复杂时，学习器会过度解读学到很多假的但是在这少数几个样本拥有的规律。


** 解决办法：**

（1）正则项：奥卡姆剃刀原则，鼓励简单模型。（过拟合的模型往往是复杂的）

（2）Dropout： 就是让神经网络在前向传播的时候，让某个神经元的激活值以一定的概率P，让他停止工作，也就是将这个神经元的激活值变为0。Dropout是非常有效的减少过拟合的方法，通俗的讲当我们挡住了数据的一部分，模型仍然能判断出数据是什么的话，说明模型的能力已经很强。同时挡住了一部分特征，能让模型不依赖于数据的某些局部特征，因为他可能已经被罢工了。
获得更多数据：过拟合问题的一个本质原因就是训练数据量不足以让模型获得整个全局特征。在少量的样本中企图观察到事物真正的规律，无异于坐井观天。当我们获得更多数据的时候，模型的眼界就会变大，就不会被局部特征所迷惑。
集成学习：简而言之，训练多个模型，以每个模型的平均输出作为结果。

（3）获得更多数据：过拟合问题的一个本质原因就是训练数据量不足以让模型获得整个全局特征。在少量的样本中企图观察到事物真正的规律，无异于坐井观天。当我们获得更多数据的时候，模型的眼界就会变大，就不会被局部特征所迷惑。

（4）集成学习：简而言之，训练多个模型，以每个模型的平均输出作为结果。


<br>
<br>
<br>
<br>



## Reference:

1.[欠拟合](https://baike.baidu.com/item/欠拟合/22692155?fr=aladdin)

2.[过拟合](https://baike.baidu.com/item/过拟合)